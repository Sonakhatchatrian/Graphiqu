{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les images les plus similaires sont :\n",
      "test_image.jpg.jpg: 591\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    dataset = []\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image = cv2.imread(os.path.join(dataset_path, filename))\n",
    "            if image is not None:\n",
    "                dataset.append((filename, image))\n",
    "    return dataset\n",
    "\n",
    "def extract_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def compare_descriptors(descriptors1, descriptors2):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return len(matches)\n",
    "\n",
    "def find_similar_images(input_image_path, dataset_path):\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    if input_image is None:\n",
    "        print(\"Erreur : l'image n'a pas été chargée correctement.\")\n",
    "        return []\n",
    "\n",
    "    _, input_descriptors = extract_features(input_image)\n",
    "    dataset = load_dataset(dataset_path)\n",
    "\n",
    "    scores = []\n",
    "    for filename, image in dataset:\n",
    "        _, descriptors = extract_features(image)\n",
    "        score = compare_descriptors(input_descriptors, descriptors)\n",
    "        scores.append((filename, score))\n",
    "\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores\n",
    "\n",
    "# Exemple d'utilisation\n",
    "input_image_path = r\"C:\\Users\\SONA8\\Desktop\\projet_eval\\chat\\chat2.jpg\"\n",
    "dataset_path = r\"C:\\Users\\SONA8\\Desktop\\projet_eval\"\n",
    "\n",
    "similar_images = find_similar_images(input_image_path, dataset_path)\n",
    "print(\"Les images les plus similaires sont :\")\n",
    "for filename, score in similar_images:\n",
    "    print(f\"{filename}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les images les plus similaires sont :\n",
      "test_image.jpg.jpg: 591\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    dataset = []\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image = cv2.imread(os.path.join(dataset_path, filename))\n",
    "            if image is not None:\n",
    "                dataset.append((filename, image))\n",
    "    return dataset\n",
    "\n",
    "def extract_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def compare_descriptors(descriptors1, descriptors2):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return len(matches)\n",
    "\n",
    "def find_similar_images(input_image_path, dataset_path):\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    if input_image is None:\n",
    "        print(\"Erreur : l'image n'a pas été chargée correctement.\")\n",
    "        return []\n",
    "\n",
    "    # Afficher l'image pour vérifier qu'elle est correctement chargée\n",
    "    cv2.imshow(\"Image d'entrée\", input_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    _, input_descriptors = extract_features(input_image)\n",
    "    dataset = load_dataset(dataset_path)\n",
    "\n",
    "    scores = []\n",
    "    for filename, image in dataset:\n",
    "        _, descriptors = extract_features(image)\n",
    "        score = compare_descriptors(input_descriptors, descriptors)\n",
    "        scores.append((filename, score))\n",
    "\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores\n",
    "\n",
    "# Exemple d'utilisation\n",
    "input_image_path = r\"C:\\Users\\SONA8\\Desktop\\projet_eval\\chat\\chat2.jpg\"\n",
    "dataset_path = r\"C:\\Users\\SONA8\\Desktop\\projet_eval\"\n",
    "\n",
    "similar_images = find_similar_images(input_image_path, dataset_path)\n",
    "print(\"Les images les plus similaires sont :\")\n",
    "for filename, score in similar_images:\n",
    "    print(f\"{filename}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m input_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSONA8\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojet_eval\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchat2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m directories \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSONA8\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojet_eval\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSONA8\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojet_eval\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlampe\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSONA8\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojet_eval\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 60\u001b[0m similar_images \u001b[38;5;241m=\u001b[39m \u001b[43mfind_similar_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLes images les plus similaires sont :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, score \u001b[38;5;129;01min\u001b[39;00m similar_images:\n",
      "Cell \u001b[1;32mIn[3], line 39\u001b[0m, in \u001b[0;36mfind_similar_images\u001b[1;34m(input_image_path, directories)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, image \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m     38\u001b[0m     _, descriptors \u001b[38;5;241m=\u001b[39m extract_features(image)\n\u001b[1;32m---> 39\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_descriptors\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_descriptors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend((filename, score))\n\u001b[0;32m     42\u001b[0m scores\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m, in \u001b[0;36mcompare_descriptors\u001b[1;34m(descriptors1, descriptors2)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_descriptors\u001b[39m(descriptors1, descriptors2):\n\u001b[0;32m     22\u001b[0m     bf \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mBFMatcher(cv2\u001b[38;5;241m.\u001b[39mNORM_L2, crossCheck\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 23\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptors1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptors2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(matches, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mdistance)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(matches)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_dataset(directories):\n",
    "    dataset = []\n",
    "    for directory in directories:\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image = cv2.imread(os.path.join(directory, filename))\n",
    "                if image is not None:\n",
    "                    dataset.append((filename, image))\n",
    "    return dataset\n",
    "\n",
    "def extract_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def compare_descriptors(descriptors1, descriptors2):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return len(matches)\n",
    "\n",
    "def find_similar_images(input_image_path, directories):\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    if input_image is None:\n",
    "        print(\"Erreur : l'image n'a pas été chargée correctement.\")\n",
    "        return []\n",
    "\n",
    "    _, input_descriptors = extract_features(input_image)\n",
    "    dataset = load_dataset(directories)\n",
    "\n",
    "    scores = []\n",
    "    for filename, image in dataset:\n",
    "        _, descriptors = extract_features(image)\n",
    "        score = compare_descriptors(input_descriptors, descriptors)\n",
    "        scores.append((filename, score))\n",
    "\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores\n",
    "\n",
    "def display_images(image_paths, dataset_path):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, (filename, score) in enumerate(image_paths[:5]):\n",
    "        image = cv2.imread(os.path.join(dataset_path, filename))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Score: {score}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "input_image_path = r\"C:\\Users\\SONA8\\Desktop\\projet_eval\\chat\\chat2.jpg\"\n",
    "directories = [r\"C:\\Users\\SONA8\\Desktop\\projet_eval\\chat\", r\"C:\\Users\\SONA8\\Desktop\\projet_eval\\lampe\", r\"C:\\Users\\SONA8\\Desktop\\projet_eval\\train\"]\n",
    "\n",
    "similar_images = find_similar_images(input_image_path, directories)\n",
    "print(\"Les images les plus similaires sont :\")\n",
    "for filename, score in similar_images:\n",
    "    print(f\"{filename}: {score}\")\n",
    "\n",
    "\n",
    "# Afficher les images les plus similaires\n",
    "display_images(similar_images, r\"C:\\Users\\SONA8\\Desktop\\projet_eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
